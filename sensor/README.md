# 👁️ Sensor (감각 - 시각 처리 시스템)

## ⚠️ 구현 상태 (Implementation Status)
- **현재 상태**: ✅ **구현 완료 (Implemented)**
    - RealSense 및 PyBullet 카메라 드라이버가 모두 구현되어 있습니다.
    - 2D 이미지를 3D 좌표로 변환하는 **역투영(Inverse Projection)** 로직이 포함되어 있습니다.

---

## 📖 개요 (Overview)
이 폴더는 로봇의 **'눈(Vision)'** 역할을 수행합니다.
단순히 사진을 찍는 것을 넘어, 사진 속의 물체가 **실제 세상(3D World)에서 어디에 위치하는지 계산**하는 수학적 로직이 핵심입니다.

---

## 📂 파일 구조 및 상세 설명 (Structure & Files)

### 1. `projection/` (폴더: 좌표 변환기)
- **`pybullet_projection.py`**: 가상 환경용 역투영 로직.
- **`realsense_projection.py`**: 실제 카메라용 역투영 로직.
- **[핵심 기능] 역투영 (Inverse Projection)이란?**:
    - 카메라는 3차원 세상을 2차원 평면(화면)으로 납작하게 만듭니다. 이를 다시 3차원으로 되돌리는 기술입니다.
    - **로직**:
        1. **Intrinsic(내부 파라미터)**: 카메라 렌즈의 특성(초점 거리 fx, fy / 중심점 cx, cy)을 가져옵니다.
        2. **Extrinsic(외부 파라미터)**: 카메라가 세상의 어디에 설치되어 있는지(위치, 회전) 행렬을 가져옵니다.
        3. **연산**: 화면상의 점 `(u, v)`와 깊이 `(depth)`를 알면, 핀홀 카메라 공식 `x = (u - cx) * depth / fx`를 역으로 계산하여 카메라 기준 3D 좌표를 얻습니다.
        4. **변환**: 카메라 기준 좌표에 `Extrinsic` 행렬을 곱해 **월드 절대 좌표(World Coordinate)**를 구합니다.

### 2. `realsense_driver.py` (실제 눈)
- **역할**: Intel RealSense 카메라 하드웨어를 제어합니다.
- **기능**: 컬러(RGB)와 깊이(Depth) 스트림을 켜고 데이터를 읽어옵니다.

### 3. `pybullet_vision.py` (가상 눈)
- **역할**: PyBullet 시뮬레이터에서 가상의 이미지를 캡처해옵니다.

### 4. `vision_bridge.py` (연결 다리)
- **역할**: 위 두 드라이버 중 하나를 선택하여, 시스템이 통일된 방식으로 이미지를 받을 수 있게 해주는 중개자입니다.

---

## ⚙️ 작동 원리 (Process Flow)

1. **이미지 캡처**: `vision_bridge`가 드라이버를 호출해 사진과 깊이 지도를 얻습니다.
2. **물체 인식**: (이 폴더 밖의) YOLO나 VLM이 사진에서 "오리"를 찾고, 그 오리의 화면 좌표 `(x: 300, y: 200)`를 줍니다.
3. **좌표 변환 요청**: 시스템이 `projection` 모듈에게 "화면 (300, 200)이 실제로는 어디야?"라고 묻습니다.
4. **거리 확인**: 해당 픽셀의 깊이(Depth) 값을 확인합니다 (예: 0.5m).
5. **역투영 계산**: `pybullet_projection.pixel_to_3d(300, 200, 0.5)`를 실행합니다.
6. **결과 반환**: "그 오리는 로봇 기준 `(X: 15cm, Y: 0cm, Z: 10cm)`에 있다"고 알려줍니다.

---

## 🔗 상속 및 관계 (Relationships)
- **사용자**: `State` (결과를 저장), `Strategy/VisualServoing` (이 좌표를 보고 팔을 움직임)
- **의존성**: `numpy` (행렬 연산), `pybullet` (시뮬레이션 행렬 계산)
