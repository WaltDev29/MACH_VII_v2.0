import time
import threading
import uuid
import asyncio
from typing import Dict, Any

from shared.config import GlobalConfig
from shared.state_broadcaster import broadcaster
from .tools import ALL_TOOLS
from .prompts import SYSTEM_INSTRUCTION
from memory.falkordb_manager import memory_manager

# LangChain Imports
from langchain_community.chat_models import ChatOllama
from langchain.agents import AgentExecutor, create_structured_chat_agent
from langchain.memory import ConversationBufferMemory
from langchain.prompts import MessagesPlaceholder
from langchain.callbacks.base import BaseCallbackHandler

from shared.intents import ActionIntent
from shared.pipeline import pipeline

class UserStopException(Exception):
    pass

class AgentBroadcasterCallback(BaseCallbackHandler):
    """
    LangChainì˜ ì‚¬ê³  ê³¼ì •(Thought)ì„ Broadcasterë¡œ ì†¡ì¶œí•˜ê³  íŒŒì´í”„ë¼ì¸ì„ íŠ¸ë¦¬ê±°í•˜ëŠ” ì½œë°± í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    ì‘ë™ ì›ë¦¬:
    1. LLMì´ ë„êµ¬ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ë‹µë³€ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ ì´ í´ë˜ìŠ¤ì˜ ë©”ì„œë“œë“¤ì´ í˜¸ì¶œë©ë‹ˆë‹¤.
    2. ìƒì„±ëœ ìƒê°(Text)ì´ë‚˜ ë„êµ¬ ì‚¬ìš©(Action) ì •ë³´ë¥¼ 'agent_thought' ì±„ë„ë¡œ ì‹¤ì‹œê°„ ë°©ì†¡í•©ë‹ˆë‹¤.
    3. ì—ì´ì „íŠ¸ê°€ ìµœì¢… ë‹µë³€ì„ ë‚´ë†“ìœ¼ë©´(on_agent_finish), ê·¸ ê²°ê³¼ë¥¼ íŒŒì´í”„ë¼ì¸ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ì‹¤ì œ ë¬¼ë¦¬ í–‰ë™ì„ ìœ ë„í•©ë‹ˆë‹¤.
    """
    def __init__(self, logic_brain_instance):
        self.brain = logic_brain_instance

    def _check_stop(self):
        if self.brain.stop_token.is_set():
            raise UserStopException("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def on_chain_start(self, serialized, inputs, **kwargs):
        self._check_stop()
        broadcaster.publish("agent_thought", ">>>> ìƒê° ì‹œì‘...")

    def on_text(self, text, **kwargs):
        self._check_stop()
        pass # ì‚¬ê³  ê³¼ì •ì˜ ë„ˆë¬´ ì¡ë‹¤í•œ í…ìŠ¤íŠ¸(ë‹¨ìˆœ í† í° ë‚˜ì—´)ëŠ” ë¡œê·¸ ì˜¤ì—¼ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì œì™¸í•©ë‹ˆë‹¤.

    def on_agent_action(self, action, **kwargs):
        self._check_stop()
        broadcaster.publish("agent_thought", f"[ë„êµ¬ ì‚¬ìš©] {action.tool}: {action.tool_input}")

    def on_tool_end(self, output, **kwargs):
        self._check_stop()

    def on_agent_finish(self, finish, **kwargs):
        self._check_stop()
        # 1. [í•µì‹¬] 7-Layer íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ íŠ¸ë¦¬ê±° (Layer 3: Brain -> Layer 4: Strategy ...)
        # LLMì´ ë„ì¶œí•œ ìµœì¢… ì˜ë„(Intent)ë¥¼ ë¬¸ìì—´ì—ì„œ ì—´ê±°í˜•(Enum)ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œìŠ¤í…œ íë¦„ì— íƒœì›ë‹ˆë‹¤.
        # ì´ ì‹œì ë¶€í„° ì—ì´ì „íŠ¸ì˜ ì‚¬ê³ ê°€ ë¬¼ë¦¬ì  í–‰ë™ ê³„íšìœ¼ë¡œ êµ¬ì²´í™”ë©ë‹ˆë‹¤.
        intent_raw = finish.return_values.get("output", "IDLE")
        
        # ë¬¸ìì—´ì„ í‘œì¤€ ActionIntent Enumìœ¼ë¡œ ë³€í™˜ (íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ ë¡œì§ê³¼ ì¤‘ë³µë˜ë”ë¼ë„ ëª…ì‹œì  ë¡œê¹…ì„ ìœ„í•´ ìˆ˜í–‰)
        intent_enum = ActionIntent.from_str(intent_raw)
        pipeline.process_brain_intent(intent_enum)
        
        # 2. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(UI)ì— ìµœì¢… ê²°ì • í†µë³´
        # ì‚¬ìš©ìê°€ í™”ë©´ì—ì„œ AIì˜ íŒë‹¨ ê²°ê³¼ë¥¼ ì¦‰ì‹œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ë°©ì†¡í•©ë‹ˆë‹¤.
        broadcaster.publish("agent_thought", f"[ìµœì¢… íŒë‹¨] {intent_enum.name} ({intent_raw[:30]}...)")
        broadcaster.publish("agent_thought", "<<<< ìƒê° ì¢…ë£Œ.")

from strategy.strategy_manager import strategy_manager

class LogicBrain:
    """
    LangChain ê¸°ë°˜ì˜ ë©”ì¸ ë…¼ë¦¬ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        # ì „ëµì  ìƒíƒœëŠ” ì´ì œ StrategyManagerê°€ ì „ë‹´í•©ë‹ˆë‹¤.
        self.stop_token = threading.Event()
        
        # 1. LLM ì´ˆê¸°í™” (Ollama)
        try:
            self.llm = ChatOllama(
                model=GlobalConfig.VLM_MODEL, 
                base_url=GlobalConfig.VLM_ENDPOINT.replace("/api/generate", ""), # base_urlì€ /api/generate ì œì™¸
                temperature=0.0
            )
            # ê°„ë‹¨í•œ í˜¸ì¶œë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
            # self.llm.invoke("test") # ì‹¤ê°€ë™ ì‹œì—ëŠ” ìƒëµ ê°€ëŠ¥ (ì‹œê°„ ë‹¨ì¶•)
        except Exception as e:
             print(f"[Brain] ë©”ì¸ VLM ì—°ê²° ì‹¤íŒ¨: {e}")
             # Fallback to local Ollama (Llama 3 or similar)
             try:
                 print("[Brain] ë¡œì»¬ Ollama(llama3)ë¡œ ì „í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                 self.llm = ChatOllama(model="llama3", temperature=0)
             except Exception as fe:
                 print(f"[Brain] ëª¨ë“  LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {fe}")
                 print("[IMPORTANT] Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                 # ê·¹ë‹¨ì ì¸ ê²½ìš° ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ë¹ˆ ëª¨ë¸ ê°ì²´ë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©
                 self.llm = None

        # 2. ë©”ëª¨ë¦¬ ì´ˆê¸°í™” (ë‹¨ìˆœ ëŒ€í™” ë§¥ë½ ìœ ì§€ìš©)
        # ConversationBufferMemory: ëŒ€í™”ì˜ ì´ë ¥ì„ ë²„í¼ì— ì €ì¥í•˜ì—¬ LLMì´ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê²Œ í•©ë‹ˆë‹¤.
        # ì£¼ì˜: ì´ê²ƒì€ ë‹¨ê¸° ë©”ëª¨ë¦¬(Session Memory)ì´ë©°, FalkorDBë¥¼ ì´ìš©í•œ ì¥ê¸° ê¸°ì–µ(Long-term Memory)ê³¼ëŠ” ë‹¤ë¦…ë‹ˆë‹¤.
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="output"
        )
        
        # 3. ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì•ˆì •ì„±ì„ ìœ„í•´ initialize_agent ì‚¬ìš©)
        from langchain.agents import initialize_agent, AgentType
        
        self.agent_executor = initialize_agent(
            tools=ALL_TOOLS, 
            llm=self.llm, 
            agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, 
            verbose=True, 
            handle_parsing_errors=True,
            memory=self.memory,
            max_iterations=15,
            agent_kwargs={
                # "prefix": SYSTEM_INSTRUCTION, # [Safety] ë³µêµ¬: ì´ì „ ì•ˆì •ì„± í™•ë³´ë¥¼ ìœ„í•´ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ë¹„í™œì„±í™”
                "memory_prompts": [MessagesPlaceholder(variable_name="chat_history")], # ëŒ€í™” ë‚´ì—­ ì£¼ì…
                "input_variables": ["input", "agent_scratchpad", "chat_history"] # ë­ì²´ì¸ í•„ìˆ˜ ì…ë ¥ ë³€ìˆ˜
            }
        )
        
        broadcaster.log_chat("bot", "MACH-VII ë‘ë‡Œ(Brain)ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def stop_agent(self):
        """ì—ì´ì „íŠ¸ ì‚¬ê³  ê°•ì œ ì¤‘ë‹¨"""
        print("[Brain] ì—ì´ì „íŠ¸ ë…¼ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤...")
        self.stop_token.set()

    async def execute_task(self, task_command: str):
        """
        ë¹„ë™ê¸°ì ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì‚¬ê³  ë£¨í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. 
        ë©”ì¸ ìŠ¤ë ˆë“œ(FastAPI ì„œë²„)ë¥¼ ì°¨ë‹¨í•˜ì§€ ì•Šê¸° ìœ„í•´ asyncio.get_event_loop().run_in_executorë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            task_command (str): ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹ (ì˜ˆ: "ì˜¤ë¦¬ë¥¼ ì§‘ì–´ì¤˜")
        """
        self.stop_token.clear() # ì‹œì‘ ì‹œ í† í° ì´ˆê¸°í™”
        
        broadcaster.log_chat("user", f"ëª…ë ¹: {task_command}")
        broadcaster.publish("agent_state", "THINKING")
        
        try:
            loop = asyncio.get_event_loop()
            # self.stop_tokenì„ ê³µìœ í•˜ê¸° ìœ„í•´ selfë¥¼ ë„˜ê¹€
            callbacks = [AgentBroadcasterCallback(self)]
            
            # [Context Injection] í˜„ì¬ ì‹œê°ì  ì¸ì§€(Perception) ìƒíƒœ ì£¼ì…
            # ì—ì´ì „íŠ¸ê°€ "ì§€ê¸ˆ ë­ê°€ ë³´ì—¬?"ë¼ê³  ë¬¼ì–´ë³´ì§€ ì•Šì•„ë„ ì•Œ ìˆ˜ ìˆë„ë¡,
            # í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ(system_state)ì— ì €ì¥ëœ ê°ì§€ëœ ë¬¼ì²´ ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ë¯¸ë¦¬ í¬í•¨ì‹œí‚µë‹ˆë‹¤.
            from state.system_state import system_state
            perception = system_state.perception_data
            
            context_str = ""
            if perception and "detected_objects" in perception:
                objects = perception["detected_objects"]
                if objects:
                    obj_list = [f"- {obj['name']} at ({obj['position']['x']}, {obj['position']['y']}, {obj['position']['z']})" for obj in objects]
                    context_str = "\n\n[í˜„ì¬ ì‹œì•¼ì— ë³´ì´ëŠ” ë¬¼ì²´ë“¤(ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)]:\n" + "\n".join(obj_list)
                else:
                    context_str = "\n\n[í˜„ì¬ ì‹œì•¼]: ë¬¼ì²´ ì—†ìŒ"
            
            # ì…ë ¥ ë©”ì‹œì§€ì— ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            full_input = f"{task_command}{context_str}"
            
            # ë™ê¸° í•¨ìˆ˜ì¸ agent_executor.invokeë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            response = await loop.run_in_executor(
                None, 
                lambda: self.agent_executor.invoke(
                    {"input": full_input},
                    {"callbacks": callbacks}
                )
            )
            
            output_msg = response.get("output", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            broadcaster.log_chat("bot", output_msg)
            broadcaster.publish("agent_state", "IDLE")

        except UserStopException:
            broadcaster.log_chat("bot", "ğŸš¨ ì‚¬ìš©ìì˜ ìš”ì²­ìœ¼ë¡œ ìƒê°ì„ ë©ˆì·„ìŠµë‹ˆë‹¤.")
            broadcaster.publish("agent_state", "IDLE")

        except Exception as e:
            err_msg = f"Brain ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(err_msg)
            broadcaster.log_chat("bot", "ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìƒê°ì„ ë©ˆì·„ìŠµë‹ˆë‹¤.")
            broadcaster.publish("agent_state", "ERROR")

# ì‹±ê¸€í†¤ ê°ì²´
logic_brain = LogicBrain()